version: "3.9"

services:
  dns:
    container_name: dns
    build:
      context: ..
      dockerfile: microservices/dns/Dockerfile
    image: tarunaws/ai:dns
    restart: always
    env_file:
      - ./dns/.env
    networks:
      envid-net:
        ipv4_address: 172.28.0.2


  backend:
    container_name: backend
    build:
      context: ..
      dockerfile: microservices/backend/Dockerfile
    image: tarunaws/ai:backend
    restart: always
    runtime: nvidia
    env_file:
      - ./.env
      - ./backend/.env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - ENVID_METADATA_SCENEDETECT_THRESHOLD=12
      - ENVID_SCENE_MIN_SECONDS=0.2
      - ENVID_SCENE_FALLBACK_MIN_SECONDS=3
      - ENVID_SCENE_FALLBACK_TARGET=12
      - ENVID_METADATA_KEY_SCENE_TOP_K=12
      - ENVID_METADATA_KEY_SCENE_MIN_GAP_SECONDS=4
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /mnt/gcs:/mnt/gcs
      - /mnt/processing:/tmp
      - /home/tarun-envid/envid-local:/tmp/envid-metadata-local
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    depends_on:
      - db
    dns:
      - 172.28.0.2
    networks:
      envid-net:
        ipv4_address: 172.28.0.4

  genai:
    container_name: genai
    build:
      context: ..
      dockerfile: microservices/llama-cpp/Dockerfile
    image: tarunaws/ai:llama-cpp
    restart: always
    environment:
      - MODEL=/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
      - HOST=0.0.0.0
      - PORT=8000
      - N_CTX=4096
      - N_THREADS=8
    volumes:
      - /mnt/data/llama_models:/models:ro
    networks:
      envid-net:
        ipv4_address: 172.28.0.19

  ingest:
    container_name: ingest
    build:
      context: ..
      dockerfile: microservices/ingest/Dockerfile
    image: tarunaws/ai:ingest
    restart: always
    env_file:
      - ./.env
      - ./ingest/.env
    volumes:
      - /mnt/gcs:/mnt/gcs
    ports:
      - "5090:5090"
    dns:
      - 172.28.0.2
    networks:
      envid-net:
        ipv4_address: 172.28.0.18

  frontend:
    container_name: frontend
    build:
      context: ..
      dockerfile: microservices/frontend/Dockerfile
    image: tarunaws/ai:frontend
    restart: always
    env_file:
      - ./frontend/.env
    volumes:
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    dns:
      - 172.28.0.2
    networks:
      envid-net:
        ipv4_address: 172.28.0.5

  audio-transcription:
    container_name: audio-transcription
    build:
      context: ..
      dockerfile: microservices/audio-transcription/Dockerfile
    image: tarunaws/ai:audio-transcription
    restart: always
    runtime: nvidia
    env_file:
      - ./.env
      - ./audio-transcription/.env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - ENVID_OPENAI_WHISPER_DEVICE=cuda
      - ENVID_OPENAI_WHISPER_COMPUTE_TYPE=float16
      - ENVID_PUNCTUATION_ENABLED=false
    volumes:
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    ports:
      - "5088:5088"
    networks:
      envid-net:
        ipv4_address: 172.28.0.6
        aliases:
          - audio-transcription
    dns:
      - 172.28.0.2

  moderation:
    container_name: moderation
    build:
      context: ..
      dockerfile: microservices/moderation/Dockerfile
    image: tarunaws/ai:moderation
    restart: always
    runtime: nvidia
    volumes:
      - /mnt/processing:/tmp
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    ports:
      - "5081:5081"
    networks:
      envid-net:
        ipv4_address: 172.28.0.7
    dns:
      - 172.28.0.2

  keyscene:
    container_name: keyscene
    build:
      context: ..
      dockerfile: microservices/keyscene/Dockerfile
    image: tarunaws/ai:keyscene
    restart: always
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TRANSNETV2_MODEL_DIR=/models/transnetv2-weights
      - TRANSNETV2_BACKEND=pytorch
      - TRANSNETV2_PYTORCH_WEIGHTS=/tmp/transnetv2-pytorch-weights.pth
      - ENVID_METADATA_KEY_SCENE_MIN_GAP_SECONDS=4
    volumes:
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
      - ./keyscene/transnetv2-weights:/models/transnetv2-weights:ro
    ports:
      - "5085:5085"
    networks:
      envid-net:
        ipv4_address: 172.28.0.8
    dns:
      - 172.28.0.2

  transcoder:
    container_name: transcoder
    build:
      context: ..
      dockerfile: microservices/transcoder/Dockerfile
    image: tarunaws/ai:transcoder
    restart: always
    runtime: nvidia
    env_file:
      - ./transcoder/.env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,video,utility
    volumes:
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
      - ./transcoder/code/ffmpeg.py:/app/ffmpeg.py
    ports:
      - "5091:5091"
    networks:
      envid-net:
        ipv4_address: 172.28.0.9

  scene-detect:
    container_name: scene-detect
    build:
      context: ..
      dockerfile: microservices/scene-detect/Dockerfile
    image: tarunaws/ai:scene-detect
    restart: always
    volumes:
      - /mnt/processing:/tmp
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    ports:
      - "5094:5094"
    dns:
      - 172.28.0.2
    networks:
      envid-net:
        ipv4_address: 172.28.0.21


  metadata-export:
    container_name: metadata-export
    build:
      context: ..
      dockerfile: microservices/metadata-export/Dockerfile
    image: tarunaws/ai:metadata-export
    restart: always
    env_file:
      - ./.env
      - ./metadata-export/.env
    volumes:
      - /tmp:/tmp
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    ports:
      - "5096:5096"
    dns:
      - 172.28.0.2
    networks:
      envid-net:
        ipv4_address: 172.28.0.23

  translate:
    container_name: translate
    build:
      context: ..
      dockerfile: microservices/translate/Dockerfile
    image: tarunaws/ai:translate
    restart: always
    env_file:
      - ./.env
      - ./translate/.env
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - HUGGINGFACE_HUB_TOKEN=${HF_TOKEN}
      - INDIC_TRANS_CACHE_DIR=/tmp/indictrans-cache
      - HF_HOME=/tmp/indictrans-cache
      - HF_HUB_CACHE=/tmp/indictrans-cache
      - TRANSFORMERS_CACHE=/tmp/indictrans-cache
      - TMPDIR=/mnt/gcs/translate/tmp
      - TEMP=/mnt/gcs/translate/tmp
      - TMP=/mnt/gcs/translate/tmp
      - TORCHINDUCTOR_CACHE_DIR=/mnt/gcs/translate/torchinductor
    ports:
      - "5000:5000"
      - "8010:8010"
      - "5098:5098"
    volumes:
      - /mnt/gcs/translate/models:/home/libretranslate/.local/share/argos-translate
      - /mnt/gcs/translate/cache:/home/libretranslate/.local/cache
      - /mnt/gcs:/mnt/gcs
    tmpfs:
      - /tmp
    dns:
      - 172.28.0.2
    networks:
      envid-net:
        ipv4_address: 172.28.0.14
        aliases:
          - translategrammer

  text-on-video:
    container_name: text-on-video
    build:
      context: ..
      dockerfile: microservices/text-on-video/Dockerfile
    image: tarunaws/ai:text-on-video
    restart: always
    runtime: nvidia
    env_file:
      - ./.env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - ENVID_METADATA_OCR_ENGINE=tesseract
      - ENVID_METADATA_OCR_MIN_CONF=0.35
      - ENVID_METADATA_OCR_ENABLE_TOP_THIRD=true
      - ENVID_METADATA_OCR_ENABLE_MIDDLE_BAND=true
      - ENVID_METADATA_OCR_MIDDLE_BAND_HEIGHT=0.4
      - ENVID_METADATA_OCR_DEDUPE_WINDOW_SECONDS=0.75
    volumes:
      - /mnt/processing:/tmp
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    ports:
      - "5083:5083"
    dns:
      - 172.28.0.2
    networks:
      envid-net:
        ipv4_address: 172.28.0.17
        aliases:
          - textonvideo


  db:
    container_name: db
    build:
      context: ..
      dockerfile: microservices/db/Dockerfile
    image: tarunaws/ai:db
    restart: always
    volumes:
      - /mnt/processing/mongo:/data/db
    ports:
      - "27017:27017"
    networks:
      envid-net:
        ipv4_address: 172.28.0.24
    dns:
      - 172.28.0.2

  mongo-express:
    container_name: mongo-express
    image: mongo-express:1.0.2-20
    restart: always
    environment:
      ME_CONFIG_MONGODB_URL: mongodb://db:27017
      ME_CONFIG_MONGODB_SERVER: db
      ME_CONFIG_MONGODB_PORT: "27017"
      ME_CONFIG_SITE_BASEURL: /db
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: pass
    depends_on:
      - db
    networks:
      envid-net:
        ipv4_address: 172.28.0.25
    dns:
      - 172.28.0.2

  reverseproxy:
    container_name: reverseproxy
    build:
      context: ..
      dockerfile: microservices/reverseproxy/Dockerfile
    image: tarunaws/ai:reverseproxy
    restart: always
    depends_on:
      - frontend
      - backend
      - mongo-express
    ports:
      - "80:80"
    volumes:
      - /mnt/gcs:/mnt/gcs
      - ${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:${GCP_CREDENTIALS_PATH:-/home/tarun-envid/gcp.json}:ro
    networks:
      envid-net:
        ipv4_address: 172.28.0.13
        aliases:
          - reverproxy
    dns:
      - 172.28.0.2

networks:
  envid-net:
    name: envid-net
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/24

volumes: {}
